# pdfからpngに直す
import pathlib
import pdf2image

pdf_files = pathlib.Path('/home/esaka/workspace/notebooks/data/icdar2013/competition-dataset-eu/').glob('*.pdf')
img_dir = pathlib.Path('/home/esaka/workspace/notebooks/data/icdar2013/competition-dataset-eu/')

for pdf_file in pdf_files:
    print(pdf_file)
    base = pdf_file.stem
    images = pdf2image.convert_from_path(pdf_file, dpi = 600)
    for index, image in enumerate(images):
        image.save(img_dir/pathlib.Path(base + '-{}.png'.format(index + 1)), 'png')

# ディレクトリファイル検索
for curDir, dirs, files in os.walk("test"):
    print('===================')
    print("現在のディレクトリ: " + curDir)
    print("内包するディレクトリ:" + dirs)
    print("内包するファイル: " + files)

# listから指定したものを消す
images.remove(images[idx])

# ディレクトリ無ければ作る
os.makedirs([作りたいディレクトリ名], exist_ok=True)

# ゼロ方向への丸め
num_test_images = np.ceil(ratio * len(images))

# stiringを右から指定した数だけ分割
test = "--0.png"
test.rsplit("-", 1)

# if文を1行で書く
i = a if a > 5 else 0

# 0除算をスコープ付けて行う
import numpy as np

a = np.array(0) 
with np.errstate(divide='ignore'):  # withスコープ内のみ制御を適用する
    divided = 1 / a
print(divided)
# -> inf

divided = 1 / a  # 無視扱いのスコープ外なので、RuntimeWarningが発生する
# -> RuntimeWarning: divide by zero encountered in true_divide

# スペック取得
from tensorflow.python.client import device_lib
device_lib.list_local_devices()

# 正規表現を使って検索や置換を行う
import re
with open(pipeline_fname) as f:
    s = f.read()
with open('pipeline_file.config', 'w') as f:
    
    # fine_tune_checkpoint
    s = re.sub('fine_tune_checkpoint: ".*?"',
               'fine_tune_checkpoint: "{}"'.format(fine_tune_checkpoint), s)
    
    # tfrecord files train and test.
    s = re.sub(
        '(input_path: ".*?)(PATH_TO_BE_CONFIGURED/train)(.*?")', 'input_path: "{}"'.format(train_record_fname), s)
    s = re.sub(
        '(input_path: ".*?)(PATH_TO_BE_CONFIGURED/val)(.*?")', 'input_path: "{}"'.format(test_record_fname), s)

    # label_map_path
    s = re.sub(
        'label_map_path: ".*?"', 'label_map_path: "{}"'.format(label_map_pbtxt_fname), s)

    # Set training batch_size.
    s = re.sub('batch_size: [0-9]+',
               'batch_size: {}'.format(batch_size), s)

    # Set training steps, num_steps
    s = re.sub('num_steps: [0-9]+',
               'num_steps: {}'.format(num_steps), s)
    
    # Set number of classes num_classes.
    s = re.sub('num_classes: [0-9]+',
               'num_classes: {}'.format(num_classes), s)
    
    #fine-tune checkpoint type
    s = re.sub(
        'fine_tune_checkpoint_type: "classification"', 'fine_tune_checkpoint_type: "{}"'.format('detection'), s)
        
    f.write(s)

# テキストファイルの操作
https://qiita.com/zaburo/items/0ba12417dfb39fcb1555

## "a"オプションは追記
## ファイルがない場合は作成される
with open(anotation_fname,'a') as f:
    anotation = "{}\t{}".format(f, anotation)
    f.write()

# pip error
-> pip install --upgrade pip setuptools

# 文字列操作
https://qiita.com/Kenta-Han/items/e64035e9c3e4ef08e394#%E6%96%87%E5%AD%97%E5%88%97%E3%81%AE%E5%89%8A%E9%99%A4

# ファイル名操作
https://note.nkmk.me/python-os-basename-dirname-split-splitext/

# autoreload
%load_ext autoreload
autoreload

# map関数の引数に取れるのイテレーターオブジェクト
https://qiita.com/conf8o/items/0cb02bc504b51af09099

# リスト内の各要素に対して操作をしたい時

mapかリスト内包表記を使うと良い

```
def matmul(x, y):
    return x*y
test1 = [1,2,3,4,5]
test2 = [3,4,5,6,7]
test_result = map(matmul, test1, test2)
print(list(test_result)) # [3,8,15,24,35]
```

```
def matmul(x, y):
    return x*y

test1 = [1,2,3,4,5]
test2 = [3,4,5,6,7]
test_result = [matmul(k, d) for k,d in zip(test1, test2)]
print(test_result) # [3,8,15,24,35]
```

# 指定した値が入った文字列と一致する値が対象リストに入っていたらto_fine_tuneにappendする文
# Select variables in top layers to fine-tune.
trainable_variables = detection_model.trainable_variables
to_fine_tune = []
prefixes_to_train = [
  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',
  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']
for var in trainable_variables:
  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):
    to_fine_tune.append(var)

## 指定していた値が対象リストに入って無かったらdeleteする文
xml_filenames = glob.glob(output_data_path + "*.xml")
png_filenames = glob.glob(output_data_path + "*.png")
for png_f in png_filenames:
    if any([os.path.splitext(png_f.split("/")[-1])[0]  == os.path.splitext(xml_f.split("/")[-1])[0] for xml_f in xml_filenames]):
         pass
    else:
        !rm {png_f}
        
xml_filenames = glob.glob(output_data_path + "*.xml")
png_filenames = glob.glob(output_data_path + "*.png")
print(len(png_filenames))
print(len(xml_filenames))


# xmlからdfに変換する操作
def xml_to_labels(annotation_file):
    with open(annotation_file) as f:
        xml_data = f.read()  # xmlファイルの内容を読み込む

    # xml操作
    root = ET.XML(xml_data)
    obj_to_int = lambda x: int(x.text)
    df_annotations = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'width', 'height', 'class_label'])
    for i, child in enumerate(root):
        if child.tag == 'filename':
            img_filename = child.text
        if child.tag == 'size':
            for subchild in child:
                if subchild.tag == 'width':
                    width = int(subchild.text)
                if subchild.tag == 'height':
                    height = int(subchild.text)
        if child.tag == 'object':
            # 各objectにname,bndboxタグが必ず1つのみついていることを想定して値を読み取る
            for subchild in child:
                if subchild.tag == 'name':
                    label = subchild.text
                if subchild.tag == 'bndbox':
                    xmin, ymin, xmax, ymax = tuple(map(obj_to_int, subchild.getchildren()))
            # BBOXの幅と高さを計算
            #w = xmax - xmin
            #h = ymax - ymin
            # DFに追加
            df_annotations = df_annotations.append(
                {'xmin': xmin, 'ymin': ymin, 'xmax': xmax, 'ymax': ymax, 'width': width, 'height': height, 'class_label': label},
                ignore_index=True
            )
    return img_filename, df_annotations
